{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f56535b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from itertools import chain \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a11d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps:0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(5,5)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    tensor = tensor.to('mps')\n",
    "print(f'Device: {tensor.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1ecaf6-5611-4e3c-be37-13da5efb854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408c3dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=False, \n",
    "                                              transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=False, train=False, \n",
    "                                             transform=transforms.Compose([transforms.ToTensor()])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feccd88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df5a4b2-0fb7-478c-8691-e6d4fa15ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "                 0: \"T-shirt/Top\",\n",
    "                 1: \"Trouser\",\n",
    "                 2: \"Pullover\",\n",
    "                 3: \"Dress\",\n",
    "                 4: \"Coat\", \n",
    "                 5: \"Sandal\", \n",
    "                 6: \"Shirt\",\n",
    "                 7: \"Sneaker\",\n",
    "                 8: \"Bag\",\n",
    "                 9: \"Ankle Boot\"\n",
    "                 }\n",
    "    \n",
    "    \n",
    "label_type_converter = lambda label: (label_mapping[label.item()] if type(label) == torch.Tensor \n",
    "                                      else label_mapping[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa89e84-7a75-4dc8-8d0e-2cdb90781d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-batch dimention: torch.Size([1000, 1, 28, 28])\n",
      "y-batch dimention: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "a = next(iter(train_loader))\n",
    "\n",
    "print(f'x-batch dimention: {a[0].size()}')\n",
    "print(f'y-batch dimention: {a[1].size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a7f0aa-01b7-4387-9814-4f3ba6b7306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data raw label - 8\n",
      "Data label - Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(train_loader))\n",
    "indx = random.randrange(image.size()[0])\n",
    "\n",
    "plt.imshow(image[indx].squeeze(), cmap=\"gray\")\n",
    "\n",
    "print(f'Data raw label - {label[indx]}')\n",
    "print(f'Data label - {label_type_converter(label[indx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1734d80c-c597-40e4-b5f9-f02e39d6c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "713f7a15-b203-4420-99f3-be570ca21062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC_1, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe716c57-84c7-4083-a91e-ebf02b26066c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf528c-5f49-44f3-8a7d-68cc178ad01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5421f92-6b2f-4782-b606-642f192f9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, (x,y) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits = model(x)\n",
    "        prob = nn.Softmax(dim=1)(logits)\n",
    "        loss = loss_fn(prob, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
    "    \n",
    "    train_loss /= size\n",
    "    \n",
    "    return train_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6988a8db-ad72-4f7e-b5e7-ce4e50667e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            logits = model(x)\n",
    "            prob = nn.Softmax(dim=1)(logits)\n",
    "            test_loss += loss_fn(prob, y).item()\n",
    "            correct += (prob.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    \n",
    "    print(f'Test error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')\n",
    "    \n",
    "    return test_loss, 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2648db48-b6af-490a-b641-af1e6cf12bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FC_1().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b89974-b600-4ec7-9671-c4492f2e24b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC_1(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af3963d3-f82d-44fb-8060-2eb456945855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits - tensor([[-0.0766, -0.0102,  0.0703,  0.0113,  0.0483, -0.0773, -0.0617, -0.0840,\n",
      "          0.0016, -0.0303]], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "prob - tensor([[0.0945, 0.1009, 0.1094, 0.1031, 0.1070, 0.0944, 0.0959, 0.0938, 0.1021,\n",
      "         0.0989]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denis/my_dev/ml-playground/venv/lib/python3.10/site-packages/torch/_tensor_str.py:115: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "# Test inference\n",
    "x = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(x)\n",
    "prob = nn.Softmax(dim=1)(logits)\n",
    "\n",
    "print(f'logits - {logits}')\n",
    "print(f'prob - {prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e672b8f-fecf-49bf-a0e7-39fd29b87ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FC().to(device)\n",
    "model = FC_1().to(device)\n",
    "\n",
    "# agenda = '/fc:28x28/512x512/512x10'\n",
    "agenda = '/fc_1:28x28/512x512/512x10'\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58ec745b-1338-411f-ab72-5f5e01eeca57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------\n",
      "loss: 2.303159 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 56.1%, Avg loss: 0.001974 \n",
      "\n",
      "Epoch 2\n",
      "-----------------------\n",
      "loss: 1.967485 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 68.2%, Avg loss: 0.001786 \n",
      "\n",
      "Epoch 3\n",
      "-----------------------\n",
      "loss: 1.760753 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 75.3%, Avg loss: 0.001723 \n",
      "\n",
      "Epoch 4\n",
      "-----------------------\n",
      "loss: 1.722840 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 77.1%, Avg loss: 0.001698 \n",
      "\n",
      "Epoch 5\n",
      "-----------------------\n",
      "loss: 1.669718 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 77.8%, Avg loss: 0.001690 \n",
      "\n",
      "Epoch 6\n",
      "-----------------------\n",
      "loss: 1.697715 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 78.6%, Avg loss: 0.001680 \n",
      "\n",
      "Epoch 7\n",
      "-----------------------\n",
      "loss: 1.674252 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 79.4%, Avg loss: 0.001673 \n",
      "\n",
      "Epoch 8\n",
      "-----------------------\n",
      "loss: 1.686059 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 79.5%, Avg loss: 0.001670 \n",
      "\n",
      "Epoch 9\n",
      "-----------------------\n",
      "loss: 1.659249 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 79.9%, Avg loss: 0.001666 \n",
      "\n",
      "Epoch 10\n",
      "-----------------------\n",
      "loss: 1.680138 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 79.9%, Avg loss: 0.001665 \n",
      "\n",
      "Epoch 11\n",
      "-----------------------\n",
      "loss: 1.658471 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 80.1%, Avg loss: 0.001663 \n",
      "\n",
      "Epoch 12\n",
      "-----------------------\n",
      "loss: 1.656511 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 79.9%, Avg loss: 0.001665 \n",
      "\n",
      "Epoch 13\n",
      "-----------------------\n",
      "loss: 1.658188 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 80.3%, Avg loss: 0.001660 \n",
      "\n",
      "Epoch 14\n",
      "-----------------------\n",
      "loss: 1.644814 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 80.6%, Avg loss: 0.001657 \n",
      "\n",
      "Epoch 15\n",
      "-----------------------\n",
      "loss: 1.618060 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 80.6%, Avg loss: 0.001657 \n",
      "\n",
      "Epoch 16\n",
      "-----------------------\n",
      "loss: 1.640466 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.1%, Avg loss: 0.001654 \n",
      "\n",
      "Epoch 17\n",
      "-----------------------\n",
      "loss: 1.656265 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 80.9%, Avg loss: 0.001654 \n",
      "\n",
      "Epoch 18\n",
      "-----------------------\n",
      "loss: 1.648894 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 80.8%, Avg loss: 0.001654 \n",
      "\n",
      "Epoch 19\n",
      "-----------------------\n",
      "loss: 1.636868 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 80.9%, Avg loss: 0.001654 \n",
      "\n",
      "Epoch 20\n",
      "-----------------------\n",
      "loss: 1.630039 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.0%, Avg loss: 0.001652 \n",
      "\n",
      "Epoch 21\n",
      "-----------------------\n",
      "loss: 1.645978 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.0%, Avg loss: 0.001653 \n",
      "\n",
      "Epoch 22\n",
      "-----------------------\n",
      "loss: 1.635690 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.4%, Avg loss: 0.001649 \n",
      "\n",
      "Epoch 23\n",
      "-----------------------\n",
      "loss: 1.614297 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.5%, Avg loss: 0.001648 \n",
      "\n",
      "Epoch 24\n",
      "-----------------------\n",
      "loss: 1.630710 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.3%, Avg loss: 0.001648 \n",
      "\n",
      "Epoch 25\n",
      "-----------------------\n",
      "loss: 1.632313 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.4%, Avg loss: 0.001650 \n",
      "\n",
      "Epoch 26\n",
      "-----------------------\n",
      "loss: 1.638658 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.5%, Avg loss: 0.001647 \n",
      "\n",
      "Epoch 27\n",
      "-----------------------\n",
      "loss: 1.626156 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.5%, Avg loss: 0.001648 \n",
      "\n",
      "Epoch 28\n",
      "-----------------------\n",
      "loss: 1.649334 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.5%, Avg loss: 0.001646 \n",
      "\n",
      "Epoch 29\n",
      "-----------------------\n",
      "loss: 1.634192 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.7%, Avg loss: 0.001646 \n",
      "\n",
      "Epoch 30\n",
      "-----------------------\n",
      "loss: 1.638098 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.7%, Avg loss: 0.001646 \n",
      "\n",
      "Epoch 31\n",
      "-----------------------\n",
      "loss: 1.638618 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.7%, Avg loss: 0.001644 \n",
      "\n",
      "Epoch 32\n",
      "-----------------------\n",
      "loss: 1.635496 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.0%, Avg loss: 0.001644 \n",
      "\n",
      "Epoch 33\n",
      "-----------------------\n",
      "loss: 1.616012 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.9%, Avg loss: 0.001644 \n",
      "\n",
      "Epoch 34\n",
      "-----------------------\n",
      "loss: 1.614012 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.9%, Avg loss: 0.001642 \n",
      "\n",
      "Epoch 35\n",
      "-----------------------\n",
      "loss: 1.628972 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.8%, Avg loss: 0.001644 \n",
      "\n",
      "Epoch 36\n",
      "-----------------------\n",
      "loss: 1.617460 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.0%, Avg loss: 0.001643 \n",
      "\n",
      "Epoch 37\n",
      "-----------------------\n",
      "loss: 1.632376 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.2%, Avg loss: 0.001641 \n",
      "\n",
      "Epoch 38\n",
      "-----------------------\n",
      "loss: 1.622129 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.1%, Avg loss: 0.001641 \n",
      "\n",
      "Epoch 39\n",
      "-----------------------\n",
      "loss: 1.638691 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.1%, Avg loss: 0.001641 \n",
      "\n",
      "Epoch 40\n",
      "-----------------------\n",
      "loss: 1.634239 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.3%, Avg loss: 0.001640 \n",
      "\n",
      "Epoch 41\n",
      "-----------------------\n",
      "loss: 1.621252 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.2%, Avg loss: 0.001640 \n",
      "\n",
      "Epoch 42\n",
      "-----------------------\n",
      "loss: 1.640957 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.0%, Avg loss: 0.001642 \n",
      "\n",
      "Epoch 43\n",
      "-----------------------\n",
      "loss: 1.629682 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.3%, Avg loss: 0.001639 \n",
      "\n",
      "Epoch 44\n",
      "-----------------------\n",
      "loss: 1.633445 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.1%, Avg loss: 0.001640 \n",
      "\n",
      "Epoch 45\n",
      "-----------------------\n",
      "loss: 1.634596 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.1%, Avg loss: 0.001641 \n",
      "\n",
      "Epoch 46\n",
      "-----------------------\n",
      "loss: 1.623533 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 81.9%, Avg loss: 0.001644 \n",
      "\n",
      "Epoch 47\n",
      "-----------------------\n",
      "loss: 1.622944 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.1%, Avg loss: 0.001640 \n",
      "\n",
      "Epoch 48\n",
      "-----------------------\n",
      "loss: 1.608340 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.2%, Avg loss: 0.001640 \n",
      "\n",
      "Epoch 49\n",
      "-----------------------\n",
      "loss: 1.603327 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.3%, Avg loss: 0.001639 \n",
      "\n",
      "Epoch 50\n",
      "-----------------------\n",
      "loss: 1.606203 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.3%, Avg loss: 0.001638 \n",
      "\n",
      "Epoch 51\n",
      "-----------------------\n",
      "loss: 1.614880 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.0%, Avg loss: 0.001642 \n",
      "\n",
      "Epoch 52\n",
      "-----------------------\n",
      "loss: 1.635609 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.3%, Avg loss: 0.001639 \n",
      "\n",
      "Epoch 53\n",
      "-----------------------\n",
      "loss: 1.617067 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 54\n",
      "-----------------------\n",
      "loss: 1.617778 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.7%, Avg loss: 0.001636 \n",
      "\n",
      "Epoch 55\n",
      "-----------------------\n",
      "loss: 1.606177 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.6%, Avg loss: 0.001637 \n",
      "\n",
      "Epoch 56\n",
      "-----------------------\n",
      "loss: 1.624655 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.5%, Avg loss: 0.001637 \n",
      "\n",
      "Epoch 57\n",
      "-----------------------\n",
      "loss: 1.616442 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.4%, Avg loss: 0.001638 \n",
      "\n",
      "Epoch 58\n",
      "-----------------------\n",
      "loss: 1.619998 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.5%, Avg loss: 0.001637 \n",
      "\n",
      "Epoch 59\n",
      "-----------------------\n",
      "loss: 1.625648 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.1%, Avg loss: 0.001641 \n",
      "\n",
      "Epoch 60\n",
      "-----------------------\n",
      "loss: 1.618528 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.5%, Avg loss: 0.001637 \n",
      "\n",
      "Epoch 61\n",
      "-----------------------\n",
      "loss: 1.613483 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.5%, Avg loss: 0.001636 \n",
      "\n",
      "Epoch 62\n",
      "-----------------------\n",
      "loss: 1.617961 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.6%, Avg loss: 0.001636 \n",
      "\n",
      "Epoch 63\n",
      "-----------------------\n",
      "loss: 1.614382 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.5%, Avg loss: 0.001636 \n",
      "\n",
      "Epoch 64\n",
      "-----------------------\n",
      "loss: 1.584104 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.7%, Avg loss: 0.001636 \n",
      "\n",
      "Epoch 65\n",
      "-----------------------\n",
      "loss: 1.614249 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.4%, Avg loss: 0.001638 \n",
      "\n",
      "Epoch 66\n",
      "-----------------------\n",
      "loss: 1.616443 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.6%, Avg loss: 0.001636 \n",
      "\n",
      "Epoch 67\n",
      "-----------------------\n",
      "loss: 1.626554 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.6%, Avg loss: 0.001636 \n",
      "\n",
      "Epoch 68\n",
      "-----------------------\n",
      "loss: 1.634360 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.6%, Avg loss: 0.001635 \n",
      "\n",
      "Epoch 69\n",
      "-----------------------\n",
      "loss: 1.614535 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001635 \n",
      "\n",
      "Epoch 70\n",
      "-----------------------\n",
      "loss: 1.610820 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 71\n",
      "-----------------------\n",
      "loss: 1.584011 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.7%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 72\n",
      "-----------------------\n",
      "loss: 1.603599 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 73\n",
      "-----------------------\n",
      "loss: 1.610485 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 74\n",
      "-----------------------\n",
      "loss: 1.593143 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.7%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 75\n",
      "-----------------------\n",
      "loss: 1.608740 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 76\n",
      "-----------------------\n",
      "loss: 1.623841 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 77\n",
      "-----------------------\n",
      "loss: 1.612393 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 78\n",
      "-----------------------\n",
      "loss: 1.611502 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 79\n",
      "-----------------------\n",
      "loss: 1.617908 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 80\n",
      "-----------------------\n",
      "loss: 1.610819 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 81\n",
      "-----------------------\n",
      "loss: 1.610103 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.7%, Avg loss: 0.001635 \n",
      "\n",
      "Epoch 82\n",
      "-----------------------\n",
      "loss: 1.635490 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.4%, Avg loss: 0.001638 \n",
      "\n",
      "Epoch 83\n",
      "-----------------------\n",
      "loss: 1.624657 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.0%, Avg loss: 0.001640 \n",
      "\n",
      "Epoch 84\n",
      "-----------------------\n",
      "loss: 1.615843 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001633 \n",
      "\n",
      "Epoch 85\n",
      "-----------------------\n",
      "loss: 1.625474 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001633 \n",
      "\n",
      "Epoch 86\n",
      "-----------------------\n",
      "loss: 1.619134 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.6%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 87\n",
      "-----------------------\n",
      "loss: 1.625529 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 88\n",
      "-----------------------\n",
      "loss: 1.604730 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.7%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 89\n",
      "-----------------------\n",
      "loss: 1.630202 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001633 \n",
      "\n",
      "Epoch 90\n",
      "-----------------------\n",
      "loss: 1.610918 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 91\n",
      "-----------------------\n",
      "loss: 1.625147 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001633 \n",
      "\n",
      "Epoch 92\n",
      "-----------------------\n",
      "loss: 1.618536 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 93\n",
      "-----------------------\n",
      "loss: 1.613711 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 94\n",
      "-----------------------\n",
      "loss: 1.606535 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 95\n",
      "-----------------------\n",
      "loss: 1.614567 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001633 \n",
      "\n",
      "Epoch 96\n",
      "-----------------------\n",
      "loss: 1.614155 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 97\n",
      "-----------------------\n",
      "loss: 1.611595 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 98\n",
      "-----------------------\n",
      "loss: 1.617183 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 99\n",
      "-----------------------\n",
      "loss: 1.616205 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 100\n",
      "-----------------------\n",
      "loss: 1.589207 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 101\n",
      "-----------------------\n",
      "loss: 1.615484 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 102\n",
      "-----------------------\n",
      "loss: 1.595574 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 103\n",
      "-----------------------\n",
      "loss: 1.597881 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 104\n",
      "-----------------------\n",
      "loss: 1.610362 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 105\n",
      "-----------------------\n",
      "loss: 1.599205 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 106\n",
      "-----------------------\n",
      "loss: 1.599002 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 107\n",
      "-----------------------\n",
      "loss: 1.610787 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 108\n",
      "-----------------------\n",
      "loss: 1.616832 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 109\n",
      "-----------------------\n",
      "loss: 1.612822 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 110\n",
      "-----------------------\n",
      "loss: 1.599357 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001633 \n",
      "\n",
      "Epoch 111\n",
      "-----------------------\n",
      "loss: 1.598322 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 112\n",
      "-----------------------\n",
      "loss: 1.629970 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 113\n",
      "-----------------------\n",
      "loss: 1.617703 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, Avg loss: 0.001633 \n",
      "\n",
      "Epoch 114\n",
      "-----------------------\n",
      "loss: 1.614638 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 115\n",
      "-----------------------\n",
      "loss: 1.600058 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 116\n",
      "-----------------------\n",
      "loss: 1.620334 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 117\n",
      "-----------------------\n",
      "loss: 1.610183 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 118\n",
      "-----------------------\n",
      "loss: 1.612588 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 119\n",
      "-----------------------\n",
      "loss: 1.609504 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 120\n",
      "-----------------------\n",
      "loss: 1.627357 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001633 \n",
      "\n",
      "Epoch 121\n",
      "-----------------------\n",
      "loss: 1.621435 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 122\n",
      "-----------------------\n",
      "loss: 1.600102 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 123\n",
      "-----------------------\n",
      "loss: 1.605133 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 124\n",
      "-----------------------\n",
      "loss: 1.614081 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 125\n",
      "-----------------------\n",
      "loss: 1.618921 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 126\n",
      "-----------------------\n",
      "loss: 1.604107 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.6%, Avg loss: 0.001634 \n",
      "\n",
      "Epoch 127\n",
      "-----------------------\n",
      "loss: 1.592983 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 128\n",
      "-----------------------\n",
      "loss: 1.621118 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 129\n",
      "-----------------------\n",
      "loss: 1.600360 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 130\n",
      "-----------------------\n",
      "loss: 1.612418 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 131\n",
      "-----------------------\n",
      "loss: 1.610347 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 132\n",
      "-----------------------\n",
      "loss: 1.587139 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, Avg loss: 0.001632 \n",
      "\n",
      "Epoch 133\n",
      "-----------------------\n",
      "loss: 1.615414 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 134\n",
      "-----------------------\n",
      "loss: 1.621606 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 135\n",
      "-----------------------\n",
      "loss: 1.602796 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 136\n",
      "-----------------------\n",
      "loss: 1.594148 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 137\n",
      "-----------------------\n",
      "loss: 1.604081 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 138\n",
      "-----------------------\n",
      "loss: 1.606547 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 139\n",
      "-----------------------\n",
      "loss: 1.606353 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 140\n",
      "-----------------------\n",
      "loss: 1.581033 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 141\n",
      "-----------------------\n",
      "loss: 1.618460 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 142\n",
      "-----------------------\n",
      "loss: 1.607068 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 143\n",
      "-----------------------\n",
      "loss: 1.619733 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 144\n",
      "-----------------------\n",
      "loss: 1.626812 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 145\n",
      "-----------------------\n",
      "loss: 1.621257 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 146\n",
      "-----------------------\n",
      "loss: 1.600029 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 147\n",
      "-----------------------\n",
      "loss: 1.608324 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 148\n",
      "-----------------------\n",
      "loss: 1.617552 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 149\n",
      "-----------------------\n",
      "loss: 1.615485 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 150\n",
      "-----------------------\n",
      "loss: 1.591272 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 151\n",
      "-----------------------\n",
      "loss: 1.613674 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 152\n",
      "-----------------------\n",
      "loss: 1.609463 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 153\n",
      "-----------------------\n",
      "loss: 1.585672 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 154\n",
      "-----------------------\n",
      "loss: 1.595817 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 155\n",
      "-----------------------\n",
      "loss: 1.619415 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 156\n",
      "-----------------------\n",
      "loss: 1.599866 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 157\n",
      "-----------------------\n",
      "loss: 1.602424 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 158\n",
      "-----------------------\n",
      "loss: 1.623628 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 159\n",
      "-----------------------\n",
      "loss: 1.608589 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 160\n",
      "-----------------------\n",
      "loss: 1.608543 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 161\n",
      "-----------------------\n",
      "loss: 1.612321 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 162\n",
      "-----------------------\n",
      "loss: 1.583611 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 163\n",
      "-----------------------\n",
      "loss: 1.601082 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 164\n",
      "-----------------------\n",
      "loss: 1.592994 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 165\n",
      "-----------------------\n",
      "loss: 1.604666 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 166\n",
      "-----------------------\n",
      "loss: 1.603843 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 167\n",
      "-----------------------\n",
      "loss: 1.612801 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 168\n",
      "-----------------------\n",
      "loss: 1.607072 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 169\n",
      "-----------------------\n",
      "loss: 1.599724 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.6%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 170\n",
      "-----------------------\n",
      "loss: 1.604645 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 171\n",
      "-----------------------\n",
      "loss: 1.597655 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 172\n",
      "-----------------------\n",
      "loss: 1.605617 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 173\n",
      "-----------------------\n",
      "loss: 1.605095 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 174\n",
      "-----------------------\n",
      "loss: 1.587526 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 175\n",
      "-----------------------\n",
      "loss: 1.607167 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 176\n",
      "-----------------------\n",
      "loss: 1.589078 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 177\n",
      "-----------------------\n",
      "loss: 1.609645 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 178\n",
      "-----------------------\n",
      "loss: 1.604521 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.6%, Avg loss: 0.001625 \n",
      "\n",
      "Epoch 179\n",
      "-----------------------\n",
      "loss: 1.608605 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 180\n",
      "-----------------------\n",
      "loss: 1.596906 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 181\n",
      "-----------------------\n",
      "loss: 1.618767 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 182\n",
      "-----------------------\n",
      "loss: 1.592006 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 183\n",
      "-----------------------\n",
      "loss: 1.604027 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 184\n",
      "-----------------------\n",
      "loss: 1.611273 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 185\n",
      "-----------------------\n",
      "loss: 1.605976 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.9%, Avg loss: 0.001623 \n",
      "\n",
      "Epoch 186\n",
      "-----------------------\n",
      "loss: 1.608125 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 187\n",
      "-----------------------\n",
      "loss: 1.613453 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001629 \n",
      "\n",
      "Epoch 188\n",
      "-----------------------\n",
      "loss: 1.605014 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 189\n",
      "-----------------------\n",
      "loss: 1.598572 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.6%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 190\n",
      "-----------------------\n",
      "loss: 1.602674 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 191\n",
      "-----------------------\n",
      "loss: 1.612559 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001628 \n",
      "\n",
      "Epoch 192\n",
      "-----------------------\n",
      "loss: 1.597822 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001625 \n",
      "\n",
      "Epoch 193\n",
      "-----------------------\n",
      "loss: 1.603037 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.8%, Avg loss: 0.001624 \n",
      "\n",
      "Epoch 194\n",
      "-----------------------\n",
      "loss: 1.596853 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 195\n",
      "-----------------------\n",
      "loss: 1.593075 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 196\n",
      "-----------------------\n",
      "loss: 1.599509 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.6%, Avg loss: 0.001626 \n",
      "\n",
      "Epoch 197\n",
      "-----------------------\n",
      "loss: 1.607500 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 198\n",
      "-----------------------\n",
      "loss: 1.592996 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 199\n",
      "-----------------------\n",
      "loss: 1.605052 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, Avg loss: 0.001627 \n",
      "\n",
      "Epoch 200\n",
      "-----------------------\n",
      "loss: 1.599976 [    0/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, Avg loss: 0.001628 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(comment=agenda)\n",
    "\n",
    "epoch = 200\n",
    "\n",
    "for t in range(epoch):\n",
    "    print(f'Epoch {t+1}\\n-----------------------')\n",
    "    \n",
    "    train_loss = train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loss, avg_acc = val_loop(test_loader, model, loss_fn)\n",
    "\n",
    "    writer.add_scalars('Losses', {'train': train_loss,\n",
    "                                  'val'  : test_loss,}, t+1)\n",
    "    writer.add_scalar('Accuracy/test', avg_acc, t+1)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1e3f9a6-5836-459a-b50d-55a488d4f997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground label    - Coat\n",
      "Predicted label - Coat / prob:1.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(test_loader))\n",
    "indx = random.randrange(image.size()[0])\n",
    "\n",
    "plt.imshow(image[indx].squeeze(), cmap=\"gray\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = image[indx]\n",
    "    x = x.to(device)\n",
    "\n",
    "    logits = model(x)\n",
    "    prob = nn.Softmax(dim=1)(logits)\n",
    "    \n",
    "    prediction = prob.argmax(1)\n",
    "    \n",
    "    print(f'Ground label    - {label_type_converter(label[indx])}')\n",
    "    print(f'Predicted label - {label_type_converter(prediction)} / prob:{prob[0][prob.argmax(1)].item():>0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46b643a7-e481-47e1-9642-268ddb9abe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "ground = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        prob = nn.Softmax(dim=1)(logits)\n",
    "        \n",
    "        predictions.append(prob.argmax(1))\n",
    "        ground.append(y)\n",
    "\n",
    "ground = [i.item() for i in list(chain.from_iterable(ground))]\n",
    "predictions = [i.item() for i in list(chain.from_iterable(predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30da2010-8221-4282-a7de-beb28d364320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for /fc_1:28x28/512x512/512x10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80      1000\n",
      "           1       0.98      0.97      0.98      1000\n",
      "           2       0.69      0.84      0.76      1000\n",
      "           3       0.87      0.91      0.89      1000\n",
      "           4       0.61      0.87      0.72      1000\n",
      "           5       0.98      0.95      0.97      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.95      0.95      0.95      1000\n",
      "           8       0.95      0.97      0.96      1000\n",
      "           9       0.95      0.98      0.96      1000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.77      0.84      0.80     10000\n",
      "weighted avg       0.77      0.84      0.80     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denis/my_dev/ml-playground/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/denis/my_dev/ml-playground/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/denis/my_dev/ml-playground/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification report for {agenda}')\n",
    "print(f'{metrics.classification_report(ground, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdceab7-62f5-4783-b3e0-eaf6bffb8205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
